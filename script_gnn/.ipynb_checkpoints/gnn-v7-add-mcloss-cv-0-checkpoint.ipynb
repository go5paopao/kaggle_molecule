{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V6からの変更点\n",
    "- MullikenChargeの予測もしてそのLossを追加する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD_IDX = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_geometric\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/b2/19eca95445f4657d6f164e3b57342f138780cca2b4a96a7f1a80707d778a/torch_geometric-1.3.0.tar.gz (102kB)\r\n",
      "\u001b[K     |████████████████████████████████| 112kB 3.4MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torch_geometric) (1.16.4)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from torch_geometric) (1.2.1)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.6/site-packages (from torch_geometric) (2.2)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from torch_geometric) (0.21.2)\r\n",
      "Collecting plyfile (from torch_geometric)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/82/d4069cbb49954d44087c37ff616cb423d3e2c0dd276378cdb4af3e3ef2ee/plyfile-0.7.tar.gz\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from torch_geometric) (0.23.4)\r\n",
      "Collecting rdflib (from torch_geometric)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/fe/630bacb652680f6d481b9febbb3e2c3869194a1a5fc3401a4a41195a2f8f/rdflib-4.2.2-py3-none-any.whl (344kB)\r\n",
      "\u001b[K     |████████████████████████████████| 348kB 10.5MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from torch_geometric) (2.9.0)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from networkx->torch_geometric) (4.4.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->torch_geometric) (0.13.2)\r\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas->torch_geometric) (2019.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.6/site-packages (from pandas->torch_geometric) (2.8.0)\r\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.6/site-packages (from rdflib->torch_geometric) (2.4.0)\r\n",
      "Collecting isodate (from rdflib->torch_geometric)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\r\n",
      "\u001b[K     |████████████████████████████████| 51kB 17.6MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from h5py->torch_geometric) (1.12.0)\r\n",
      "Building wheels for collected packages: torch-geometric, plyfile\r\n",
      "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for torch-geometric: filename=torch_geometric-1.3.0-cp36-none-any.whl size=176110 sha256=c3fc23e8d354333cf75021cb8f5103055234bbf0792e560c38060e7b021408d4\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/8b/4e/11/af2fec628d830776b6d49ad4df019d8200d138380d1fae39c2\r\n",
      "  Building wheel for plyfile (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for plyfile: filename=plyfile-0.7-cp36-none-any.whl size=8239 sha256=a94bc4aefb0d9993b4647b5816f52b6355640cd236fda16084558af177f88e85\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/91/3e/ee/e5630ef0fd53cedaa6e911ba27e8b40fff034388d1f264bb92\r\n",
      "Successfully built torch-geometric plyfile\r\n",
      "Installing collected packages: plyfile, isodate, rdflib, torch-geometric\r\n",
      "Successfully installed isodate-0.6.0 plyfile-0.7 rdflib-4.2.2 torch-geometric-1.3.0\r\n",
      "Collecting torch_scatter\r\n",
      "  Downloading https://files.pythonhosted.org/packages/35/d4/750403a8aa32cdb3d2d05849c6a10e4e0604de5e0cc94b81a0d0d69a75f3/torch_scatter-1.3.1.tar.gz\r\n",
      "Building wheels for collected packages: torch-scatter\r\n",
      "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for torch-scatter: filename=torch_scatter-1.3.1-cp36-cp36m-linux_x86_64.whl size=2863934 sha256=fadd6fd2f10f5bc3f74cf88ca865a7167b39975ad1acb724a9eff8375e1fae0c\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/7f/21/0b/c42fa9353ceec5e87464599e470a03e4250ec667b4a392fa7d\r\n",
      "Successfully built torch-scatter\r\n",
      "Installing collected packages: torch-scatter\r\n",
      "Successfully installed torch-scatter-1.3.1\r\n",
      "Collecting torch_sparse\r\n",
      "  Downloading https://files.pythonhosted.org/packages/b0/0a/2ff678e0d04e524dd2cf990a6202ced8c0ffe3fe6b08e02f25cc9fd27da0/torch_sparse-0.4.0.tar.gz\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from torch_sparse) (1.2.1)\r\n",
      "Building wheels for collected packages: torch-sparse\r\n",
      "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for torch-sparse: filename=torch_sparse-0.4.0-cp36-cp36m-linux_x86_64.whl size=3822636 sha256=db700126572e9ea1198daff544d1f240cf0a7a63991c3f933485bd341212bf78\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/9d/83/0a/38ea460df5586a075b877fe089619e5238487712a0645940bd\r\n",
      "Successfully built torch-sparse\r\n",
      "Installing collected packages: torch-sparse\r\n",
      "Successfully installed torch-sparse-0.4.0\r\n",
      "Collecting torch_cluster\r\n",
      "  Downloading https://files.pythonhosted.org/packages/49/0d/f7151fb6aad5c9b0e032e46c0678e0404870de4add35b0723fc2a5c4af35/torch_cluster-1.4.3.tar.gz\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from torch_cluster) (1.2.1)\r\n",
      "Building wheels for collected packages: torch-cluster\r\n",
      "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for torch-cluster: filename=torch_cluster-1.4.3-cp36-cp36m-linux_x86_64.whl size=15447488 sha256=6a30339275fa5b6254828f688c2efb6640d363dc3411632b0e6a91e20a555b75\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/e5/43/44/f48fe189a54ce1177a6bdeb8eefc332d8cedf511dd35175a74\r\n",
      "Successfully built torch-cluster\r\n",
      "Installing collected packages: torch-cluster\r\n",
      "Successfully installed torch-cluster-1.4.3\r\n",
      "Collecting dscribe\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/a5/fe085985e00b93d4a647fe24519bbaba3efe9d7c2e7efd6ef72107e8040f/dscribe-0.2.8.tar.gz (145kB)\r\n",
      "\u001b[K     |████████████████████████████████| 153kB 3.4MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from dscribe) (1.16.4)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from dscribe) (1.2.1)\r\n",
      "Collecting ase (from dscribe)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/06/ccbdfa2a7ba6b12e1225d98efc930cc244d8673885c00dab89e8bed79037/ase-3.18.0-py3-none-any.whl (2.0MB)\r\n",
      "\u001b[K     |████████████████████████████████| 2.0MB 28.8MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from dscribe) (0.17.1)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from dscribe) (0.21.2)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from dscribe) (0.13.2)\r\n",
      "Collecting soaplite==1.0.3 (from dscribe)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/d2/164ae157724e182ba0b7549f0acfdfbcc87cb707009c52b56353d52750c2/soaplite-1.0.3.tar.gz (45kB)\r\n",
      "\u001b[K     |████████████████████████████████| 51kB 19.6MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: flask in /opt/conda/lib/python3.6/site-packages (from ase->dscribe) (1.1.1)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (from ase->dscribe) (3.0.3)\r\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/lib/python3.6/site-packages (from flask->ase->dscribe) (0.15.4)\r\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/lib/python3.6/site-packages (from flask->ase->dscribe) (7.0)\r\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/lib/python3.6/site-packages (from flask->ase->dscribe) (2.10.1)\r\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/lib/python3.6/site-packages (from flask->ase->dscribe) (1.1.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib->ase->dscribe) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->ase->dscribe) (1.1.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->ase->dscribe) (2.4.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->ase->dscribe) (2.8.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from Jinja2>=2.10.1->flask->ase->dscribe) (1.1.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from cycler>=0.10->matplotlib->ase->dscribe) (1.12.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->ase->dscribe) (41.0.1)\r\n",
      "Building wheels for collected packages: dscribe, soaplite\r\n",
      "  Building wheel for dscribe (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for dscribe: filename=dscribe-0.2.8-cp36-cp36m-linux_x86_64.whl size=882869 sha256=61419d026aa6814eff9572b36ec81b68bed7f1c0e16c6d9d171c3fe18bd0cca4\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/95/f8/3f/bae4d23280bda2e4604da9e4a66462f4edc6e55c746696017f\r\n",
      "  Building wheel for soaplite (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for soaplite: filename=soaplite-1.0.3-cp36-cp36m-linux_x86_64.whl size=134051 sha256=3d5d2064bb14272cb5ac4ef8dd267a2321426ff75ef7ab69d9e8204acc99cc0a\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/51/7a/31/5bdd08b5da77d72c73e58717849a183408b5117ff7a29f5013\r\n",
      "Successfully built dscribe soaplite\r\n",
      "Installing collected packages: ase, soaplite, dscribe\r\n",
      "Successfully installed ase-3.18.0 dscribe-0.2.8 soaplite-1.0.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_geometric\n",
    "!pip install torch_scatter\n",
    "!pip install torch_sparse\n",
    "!pip install torch_cluster\n",
    "!pip install dscribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# std libs\n",
    "import numpy as np\n",
    "import os,gc,math,time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import collections,copy,numbers,inspect,shutil,random,itertools\n",
    "from timeit import default_timer as timer\n",
    "from collections import OrderedDict\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing as mp\n",
    "#from pprintpp import pprint, pformat\n",
    "import json,zipfile,csv,pickle,glob,sys,time\n",
    "import pandas as pd\n",
    "from distutils.dir_util import copy_tree\n",
    "# torch libs\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import *\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.parallel.data_parallel import data_parallel\n",
    "from torch.nn.utils.rnn import *\n",
    "# for gnn\n",
    "import torch_geometric.nn as gnn\n",
    "# add\n",
    "from sklearn.model_selection import GroupKFold\n",
    "# add\n",
    "from dscribe.descriptors import ACSF\n",
    "from dscribe.core.system import System\n",
    "from torch_scatter import *\n",
    "from torch_geometric.utils import scatter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tset random seed\n",
      "\t\tSEED = 1564744342\n",
      "\tset cuda environment\n",
      "\t\ttorch.__version__              = 1.1.0\n",
      "\t\ttorch.version.cuda             = 10.0.130\n",
      "\t\ttorch.backends.cudnn.version() = 7501\n",
      "\t\tos['CUDA_VISIBLE_DEVICES']     = None\n",
      "\t\ttorch.cuda.device_count()      = 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "COMMON_STRING =''\n",
    "\n",
    "SEED = int(time.time()) #35202   #35202  #123  #\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "COMMON_STRING += '\\tset random seed\\n'\n",
    "COMMON_STRING += '\\t\\tSEED = %d\\n'%SEED\n",
    "\n",
    "torch.backends.cudnn.benchmark     = True  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
    "torch.backends.cudnn.enabled       = True\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "COMMON_STRING += '\\tset cuda environment\\n'\n",
    "COMMON_STRING += '\\t\\ttorch.__version__              = %s\\n'%torch.__version__\n",
    "COMMON_STRING += '\\t\\ttorch.version.cuda             = %s\\n'%torch.version.cuda\n",
    "COMMON_STRING += '\\t\\ttorch.backends.cudnn.version() = %s\\n'%torch.backends.cudnn.version()\n",
    "try:\n",
    "    COMMON_STRING += '\\t\\tos[\\'CUDA_VISIBLE_DEVICES\\']     = %s\\n'%os.environ['CUDA_VISIBLE_DEVICES']\n",
    "    NUM_CUDA_DEVICES = len(os.environ['CUDA_VISIBLE_DEVICES'].split(','))\n",
    "except Exception:\n",
    "    COMMON_STRING += '\\t\\tos[\\'CUDA_VISIBLE_DEVICES\\']     = None\\n'\n",
    "    NUM_CUDA_DEVICES = 1\n",
    "\n",
    "COMMON_STRING += '\\t\\ttorch.cuda.device_count()      = %d\\n'%torch.cuda.device_count()\n",
    "#print ('\\t\\ttorch.cuda.current_device()    =', torch.cuda.current_device())\n",
    "print(COMMON_STRING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle_from_file(pickle_file):\n",
    "    with open(pickle_file,'rb') as f:\n",
    "        x = pickle.load(f)\n",
    "    return x\n",
    "\n",
    "def write_pickle_to_file(pickle_file, x):\n",
    "    with open(pickle_file, 'wb') as f:\n",
    "        pickle.dump(x, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/questions/34950201/pycharm-print-end-r-statement-not-working\n",
    "class Logger(object):\n",
    "    def __init__(self):\n",
    "        self.terminal = sys.stdout  #stdout\n",
    "        self.file = None\n",
    "\n",
    "    def open(self, file, mode=None):\n",
    "        if mode is None: mode ='w'\n",
    "        self.file = open(file, mode)\n",
    "\n",
    "    def write(self, message, is_terminal=1, is_file=1 ):\n",
    "        if '\\r' in message: is_file=0\n",
    "\n",
    "        if is_terminal == 1:\n",
    "            self.terminal.write(message)\n",
    "            self.terminal.flush()\n",
    "            #time.sleep(1)\n",
    "\n",
    "        if is_file == 1:\n",
    "            self.file.write(message)\n",
    "            self.file.flush()\n",
    "\n",
    "    def flush(self):\n",
    "        # this flush method is needed for python 3 compatibility.\n",
    "        # this handles the flush command by doing nothing.\n",
    "        # you might want to specify some extra behavior here.\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/1855095/how-to-create-a-zip-archive-of-a-directory\n",
    "def backup_project_as_zip(project_dir, zip_file):\n",
    "    assert(os.path.isdir(project_dir))\n",
    "    assert(os.path.isdir(os.path.dirname(zip_file)))\n",
    "    shutil.make_archive(zip_file.replace('.zip',''), 'zip', project_dir)\n",
    "    pass\n",
    "def time_to_str(t, mode='min'):\n",
    "    if mode=='min':\n",
    "        t  = int(t)/60\n",
    "        hr = t//60\n",
    "        min = t%60\n",
    "        return '%2d hr %02d min'%(hr,min)\n",
    "\n",
    "    elif mode=='sec':\n",
    "        t   = int(t)\n",
    "        min = t//60\n",
    "        sec = t%60\n",
    "        return '%2d min %02d sec'%(min,sec)\n",
    "\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NullScheduler():\n",
    "    def __init__(self, lr=0.01 ):\n",
    "        super(NullScheduler, self).__init__()\n",
    "        self.lr    = lr\n",
    "        self.cycle = 0\n",
    "\n",
    "    def __call__(self, time):\n",
    "        return self.lr\n",
    "\n",
    "    def __str__(self):\n",
    "        string = 'NullScheduler\\n' \\\n",
    "                + 'lr=%0.5f '%(self.lr)\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearBn(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, act=None):\n",
    "        super(LinearBn, self).__init__()\n",
    "        self.linear = nn.Linear(in_channel, out_channel, bias=False)\n",
    "        self.bn   = nn.BatchNorm1d(out_channel,eps=1e-05, momentum=0.1)\n",
    "        self.act  = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.act is not None:\n",
    "            x = self.act(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConv(nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim ):\n",
    "        super(GraphConv, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            LinearBn(edge_dim, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            LinearBn(256, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            LinearBn(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            LinearBn(128, node_dim * node_dim),\n",
    "            #nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.gru  = nn.GRU(node_dim, node_dim, batch_first=False, bidirectional=False)\n",
    "        self.bias = nn.Parameter(torch.Tensor(node_dim))\n",
    "        self.bias.data.uniform_(-1.0 / math.sqrt(node_dim), 1.0 / math.sqrt(node_dim))\n",
    "\n",
    "\n",
    "    def forward(self, node, edge_index, edge, hidden):\n",
    "        num_node, node_dim = node.shape\n",
    "        num_edge, edge_dim = edge.shape\n",
    "        edge_index = edge_index.t().contiguous()\n",
    "\n",
    "        #1. message :  m_j = SUM_i f(n_i, n_j, e_ij)  where i is neighbour(j)\n",
    "        x_i     = torch.index_select(node, 0, edge_index[0])\n",
    "        edge    = self.encoder(edge).view(-1,node_dim,node_dim)\n",
    "        #message = x_i.view(-1,node_dim,1)*edge\n",
    "        #message = message.sum(1)\n",
    "        message = x_i.view(-1,1,node_dim)@edge\n",
    "        message = message.view(-1,node_dim)\n",
    "        message = scatter_('mean', message, edge_index[1], dim_size=num_node)\n",
    "        message = F.relu(message +self.bias)\n",
    "\n",
    "        #2. update: n_j = f(n_j, m_j)\n",
    "        update = message\n",
    "\n",
    "        #batch_first=True\n",
    "        update, hidden = self.gru(update.view(1,-1,node_dim), hidden)\n",
    "        update = update.view(-1,node_dim)\n",
    "\n",
    "        return update, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Set2Set(torch.nn.Module):\n",
    "\n",
    "    def softmax(self, x, index, num=None):\n",
    "        x = x -  scatter_max(x, index, dim=0, dim_size=num)[0][index]\n",
    "        x = x.exp()\n",
    "        x = x / (scatter_add(x, index, dim=0, dim_size=num)[index] + 1e-16)\n",
    "        return x\n",
    "\n",
    "    def __init__(self, in_channel, processing_step=1):\n",
    "        super(Set2Set, self).__init__()\n",
    "        num_layer = 1\n",
    "        out_channel = 2 * in_channel\n",
    "\n",
    "        self.processing_step = processing_step\n",
    "        self.in_channel  = in_channel\n",
    "        self.out_channel = out_channel\n",
    "        self.num_layer   = num_layer\n",
    "        self.lstm = torch.nn.LSTM(out_channel, in_channel, num_layer)\n",
    "        self.lstm.reset_parameters()\n",
    "\n",
    "    def forward(self, x, batch_index):\n",
    "        batch_size = batch_index.max().item() + 1\n",
    "\n",
    "        h = (x.new_zeros((self.num_layer, batch_size, self.in_channel)),\n",
    "             x.new_zeros((self.num_layer, batch_size, self.in_channel)))\n",
    "\n",
    "        q_star = x.new_zeros(batch_size, self.out_channel)\n",
    "        for i in range(self.processing_step):\n",
    "            q, h = self.lstm(q_star.unsqueeze(0), h)\n",
    "            q = q.view(batch_size, -1)\n",
    "\n",
    "            e = (x * q[batch_index]).sum(dim=-1, keepdim=True) #shape = num_node x 1\n",
    "            a = self.softmax(e, batch_index, num=batch_size)   #shape = num_node x 1\n",
    "            r = scatter_add(a * x, batch_index, dim=0, dim_size=batch_size) #apply attention #shape = batch_size x ...\n",
    "            q_star = torch.cat([q, r], dim=-1)\n",
    "\n",
    "        return q_star\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#message passing\n",
    "class Net3(torch.nn.Module):\n",
    "    def __init__(self, node_dim=13, edge_dim=5, num_target=8):\n",
    "        super(Net3, self).__init__()\n",
    "        self.num_target = num_target\n",
    "        self.num_propagate = 6\n",
    "        self.num_s2s = 6\n",
    "\n",
    "        self.preprocess = nn.Sequential(\n",
    "            LinearBn(node_dim, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            LinearBn(128, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.propagate = GraphConv(128, edge_dim)\n",
    "        self.set2set = Set2Set(128, processing_step=self.num_s2s)\n",
    "\n",
    "\n",
    "        #predict coupling constant\n",
    "        \n",
    "        for i in range(num_target):\n",
    "            setattr(self, \n",
    "                \"type_predicts_{}\".format(i),\n",
    "                nn.Sequential(\n",
    "                    LinearBn(4*128, 1024), \n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Linear(1024, 512),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Linear(512, 256),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Linear(256, 1),\n",
    "                )\n",
    "            )\n",
    "        self.mc_predict = nn.Sequential(\n",
    "                    LinearBn(128, 512), \n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Linear(512, 256),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Linear(256, 1),\n",
    "                )\n",
    "\n",
    "    def forward(self, node, edge, edge_index, node_index, coupling_index):\n",
    "\n",
    "        num_node, node_dim = node.shape\n",
    "        num_edge, edge_dim = edge.shape\n",
    "        node   = self.preprocess(node)\n",
    "        hidden = node.view(1,num_node,-1)\n",
    "\n",
    "        for i in range(self.num_propagate):\n",
    "            node, hidden =  self.propagate(node, edge_index, edge, hidden)\n",
    "\n",
    "        pool = self.set2set(node, node_index)\n",
    "\n",
    "        #---\n",
    "        num_coupling = len(coupling_index)\n",
    "        coupling_atom0_index, coupling_atom1_index, coupling_type_index, coupling_batch_index = \\\n",
    "            torch.split(coupling_index,1,dim=1)\n",
    "        predicts = []\n",
    "        for i in range(self.num_target):\n",
    "            pool_i  = torch.index_select( pool, dim=0, index=coupling_batch_index.view(-1))\n",
    "            node0_i = torch.index_select( node, dim=0, index=coupling_atom0_index.view(-1))\n",
    "            node1_i = torch.index_select( node, dim=0, index=coupling_atom1_index.view(-1))\n",
    "            #pool_i  = torch.index_select( pool, dim=0, index=coupling_batch_index[coupling_type_index==i].view(-1))\n",
    "            #node0_i = torch.index_select( node, dim=0, index=coupling_atom0_index[coupling_type_index==i].view(-1))\n",
    "            #node1_i = torch.index_select( node, dim=0, index=coupling_atom1_index[coupling_type_index==i].view(-1))\n",
    "            x = torch.cat([pool_i,node0_i,node1_i],-1)\n",
    "            pred_func = getattr(self, \"type_predicts_{}\".format(i))\n",
    "            type_predict = pred_func(x)\n",
    "            predicts.append(type_predict)        \n",
    "        predict = torch.cat(predicts, -1)\n",
    "        predict = torch.gather(predict, 1, coupling_type_index).view(-1)\n",
    "        # mc predict\n",
    "        pool_mc = torch.index_select( pool, dim=0, index=coupling_batch_index.view(-1))\n",
    "        #mc_x = torch.cat([pool,node],-1)\n",
    "        #いったんpool使わない\n",
    "        mc_x = node\n",
    "        mc_predict = self.mc_predict(mc_x).view(-1)\n",
    "        #predict = predict.view(-1)\n",
    "        return predict, mc_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_split, valid_split = get_split(FOLD_IDX)\n",
    "tmpdata = ChampsDataset(\n",
    "            csv='train',\n",
    "            mode ='train',\n",
    "            split = train_split,\n",
    "            #split='debug_split_by_mol.1000.npy', #\n",
    "            #split='train_split_by_mol.80003.npy',\n",
    "            augment=None,\n",
    ")\n",
    "tmp_loader  = DataLoader(\n",
    "            tmpdata,\n",
    "            #sampler     = SequentialSampler(train_dataset),\n",
    "            sampler     = RandomSampler(tmpdata),\n",
    "            batch_size  = 2,\n",
    "            drop_last   = True,\n",
    "            num_workers = 16,\n",
    "            pin_memory  = True,\n",
    "            collate_fn  = null_collate\n",
    ")\n",
    "for data in tmp_loader:\n",
    "    tmp = data\n",
    "    break\n",
    "\"\"\"\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kaggle_metric( predict, coupling_value, coupling_type):\n",
    "\n",
    "    mae     = [None]*NUM_TARGET\n",
    "    log_mae = [None]*NUM_TARGET\n",
    "    diff = np.fabs(predict-coupling_value)\n",
    "    for t in range(NUM_TARGET):\n",
    "        index = np.where(coupling_type==t)[0]\n",
    "        if len(index)>0:\n",
    "            m = diff[index].mean()\n",
    "            log_m = np.log(m+1e-8)\n",
    "\n",
    "            mae[t] = m\n",
    "            log_mae[t] = log_m\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return mae, log_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(predict, coupling_value, mc_predict, mc):\n",
    "    #predict = predict.view(-1)\n",
    "    #coupling_value = coupling_value.view(-1)\n",
    "    #assert(predict.shape==coupling_value.shape)\n",
    "    #loss = F.mse_loss(predict, coupling_value)\n",
    "    #return loss\n",
    "    predict = predict.view(-1)\n",
    "    truth   = coupling_value.view(-1)\n",
    "    assert(predict.shape==truth.shape)\n",
    "\n",
    "    loss = torch.abs(predict-truth)\n",
    "    loss = loss.mean()\n",
    "    mc_loss = torch.abs(mc_predict.view(-1)- mc.view(-1))\n",
    "    mc_loss = torch.log(mc_loss.mean())\n",
    "    loss = torch.log(loss)\n",
    "    \n",
    "    #print(loss)\n",
    "    #time.sleep(1)\n",
    "    return loss+mc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(fold_idx):\n",
    "    \"\"\"\n",
    "    Validationをローカルのpair単位のCrossValidationのindexに合わせる\n",
    "    \"\"\"\n",
    "    csv_file = '../input/champs-scalar-coupling/train.csv'\n",
    "    train_df  = pd.read_csv(csv_file)\n",
    "    fold_num = 3\n",
    "    random_state = 2019\n",
    "    folds = GroupKFold(n_splits = fold_num)\n",
    "    split_index_list = [(trn_, val_) for trn_, val_ \n",
    "                        in folds.split(train_df, train_df[\"scalar_coupling_constant\"], groups=train_df[\"molecule_name\"])]\n",
    "    molecule_names = train_df.molecule_name.unique()\n",
    "    \n",
    "    use_fold_idx = split_index_list[fold_idx]\n",
    "    train_split = train_df.loc[use_fold_idx[0],\"molecule_name\"].unique()\n",
    "    valid_split = train_df.loc[use_fold_idx[1],\"molecule_name\"].unique()\n",
    "    #molecule_names = train_df.molecule_name.unique()\n",
    "    #molecule_names = np.sort(molecule_names)\n",
    "    #np.random.shuffle(molecule_names)\n",
    "    #num_all   = len(molecule_names)\n",
    "    #num_valid = 5000\n",
    "    #num_train = num_all - num_valid\n",
    "    #train_split = molecule_names[num_valid:]\n",
    "    #valid_split = molecule_names[:num_valid]\n",
    "    return train_split, valid_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def get_learning_rate(optimizer):\n",
    "    lr=[]\n",
    "    for param_group in optimizer.param_groups:\n",
    "       lr +=[ param_group['lr'] ]\n",
    "\n",
    "    assert(len(lr)==1) #we support only one param_group\n",
    "    lr = lr[0]\n",
    "\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "DATA_DIR = '../input'\n",
    "GRAPH = None\n",
    "GRAPH_MAPPING = None\n",
    "SYMBOL=['H', 'C', 'N', 'O', 'F']\n",
    "ACSF_GENERATOR = ACSF(\n",
    "    species = SYMBOL,\n",
    "    rcut = 6.0,\n",
    "    g2_params=[[1, 1], [1, 2], [1, 3]],\n",
    "    g4_params=[[1, 1, 1], [1, 2, 1], [1, 1, -1], [1, 2, -1]],\n",
    ")\n",
    "\n",
    "\n",
    "class ChampsDataset(Dataset):\n",
    "    def __init__(self, split, csv, mode, augment=None):\n",
    "\n",
    "        self.split   = split\n",
    "        self.csv     = csv\n",
    "        self.mode    = mode\n",
    "        self.augment = augment\n",
    "\n",
    "        self.df = pd.read_csv(DATA_DIR + '/champs-scalar-coupling/%s.csv'%csv)\n",
    "\n",
    "        #if split is not None:\n",
    "        #    self.id = np.load(DATA_DIR + '/split/%s'%split,allow_pickle=True)\n",
    "        #else:\n",
    "        #    self.id = self.df.molecule_name.unique()\n",
    "        self.id = split\n",
    "        #zz=0\n",
    "        #self.dummy_graph = read_pickle_from_file(DATA_DIR + '/structure/graph/dsgdb9nsd_000001.pickle')\n",
    "\n",
    "    def __str__(self):\n",
    "            string = ''\\\n",
    "            + '\\tmode   = %s\\n'%self.mode \\\n",
    "            + '\\tsplit  = %s\\n'%self.split \\\n",
    "            + '\\tcsv    = %s\\n'%self.csv \\\n",
    "            + '\\tlen    = %d\\n'%len(self)\n",
    "\n",
    "            return string\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.id)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        molecule_name = self.id[index]\n",
    "        #graph_file = DATA_DIR + '/atoms-graph/graph/graph/%s.pickle'%molecule_name\n",
    "        #graph_file = DATA_DIR + '/graph-v4/graph_v4/graph_v4/%s.pickle'%molecule_name\n",
    "        graph_file = DATA_DIR + \\\n",
    "        '/graph-v5/var/kaggle/tmp/a40d44cf-b5e4-4b90-9e71-17285bd76a4c/data/graph_v5/%s.pickle'%molecule_name\n",
    "        #graph_file = DATA_DIR + '/graph-v5/graph_v5/graph_v5/%s.pickle'%molecule_name\n",
    "        #graph_file = DATA_DIR + '/molecule-graph/graph_v2/graph_v2/%s.pickle'%molecule_name\n",
    "        graph = list(read_pickle_from_file(graph_file))\n",
    "        assert(graph[0]==molecule_name)\n",
    "\n",
    "        # ##filter only J link\n",
    "        # if 0:\n",
    "        #     # 1JHC,     2JHC,     3JHC,     1JHN,     2JHN,     3JHN,     2JHH,     3JHH\n",
    "        #     mask = np.zeros(len(graph.coupling.type),np.bool)\n",
    "        #     for t in ['1JHC',     '2JHH']:\n",
    "        #         mask += (graph.coupling.type == COUPLING_TYPE.index(t))\n",
    "        #\n",
    "        #     graph.coupling.id = graph.coupling.id [mask]\n",
    "        #     graph.coupling.contribution = graph.coupling.contribution [mask]\n",
    "        #     graph.coupling.index = graph.coupling.index [mask]\n",
    "        #     graph.coupling.type = graph.coupling.type [mask]\n",
    "        #     graph.coupling.value = graph.coupling.value [mask]\n",
    "        # test mcを除く\n",
    "        #graph[3] = graph[3][:-2]\n",
    "        #graph[4] = graph[4][:-1]\n",
    "        if 1:\n",
    "            atom = System(symbols =graph[2][0], positions=graph[2][1])\n",
    "            acsf = ACSF_GENERATOR.create(atom)\n",
    "            graph[3] += [acsf,]\n",
    "\n",
    "        # if 1:\n",
    "        #     graph.edge = graph.edge[:-1]\n",
    "        graph[g_node_idx][7] = graph[g_node_idx][7].reshape([-1,1])\n",
    "\n",
    "        graph[3] = np.concatenate(graph[3],-1)\n",
    "        graph[4] = np.concatenate(graph[4],-1)\n",
    "        graph[3][np.isnan(graph[3])] = 0\n",
    "        graph[4][np.isnan(graph[4])] = 0\n",
    "        if np.isnan(graph[3]).sum()>0 or np.isnan(graph[4]).sum() > 0:\n",
    "            print(graph)\n",
    "        #print(graph[3].shape, graph[4].shape)\n",
    "        #time.sleep(3)\n",
    "        return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_molecule_name_idx = 0\n",
    "g_smile_idx = 1\n",
    "g_atom_idx = 2\n",
    "g_node_idx = 3\n",
    "g_edge_idx = 4\n",
    "g_edge_index_idx = 5\n",
    "g_coupling_idx = 6\n",
    "c_id_idx = 0\n",
    "c_contribution_idx = 1\n",
    "c_index_idx = 2\n",
    "c_type_idx = 3\n",
    "c_value_idx = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_collate(batch):\n",
    "    batch_size = len(batch)\n",
    "\n",
    "    node = []\n",
    "    edge = []\n",
    "    edge_index = []\n",
    "    node_index = []\n",
    "\n",
    "    coupling_value = []\n",
    "    coupling_atom_index  = []\n",
    "    coupling_type_index  = []\n",
    "    coupling_batch_index = []\n",
    "    infor = []\n",
    "\n",
    "    offset = 0\n",
    "    for b in range(batch_size):\n",
    "        graph = batch[b]\n",
    "        #print(graph.molecule_name)\n",
    "\n",
    "        num_node = len(graph[g_node_idx])\n",
    "        node.append(graph[g_node_idx])\n",
    "        edge.append(graph[g_edge_idx])\n",
    "        edge_index.append(graph[g_edge_index_idx]+offset)\n",
    "        node_index.append(np.array([b]*num_node))\n",
    "\n",
    "        num_coupling = len(graph[g_coupling_idx][0])\n",
    "        coupling_value.append(graph[g_coupling_idx][c_value_idx])\n",
    "        coupling_atom_index.append(graph[g_coupling_idx][c_index_idx]+offset)\n",
    "        coupling_type_index.append (graph[g_coupling_idx][c_type_idx])\n",
    "        coupling_batch_index.append(np.array([b]*num_coupling))\n",
    "\n",
    "        infor.append((graph[g_molecule_name_idx], graph[g_smile_idx], graph[g_coupling_idx][c_id_idx]))\n",
    "        offset += num_node\n",
    "        #print(num_node, len(coupling_batch_index))\n",
    "\n",
    "    node = torch.from_numpy(np.concatenate(node)).float()\n",
    "    edge = torch.from_numpy(np.concatenate(edge)).float()\n",
    "    edge_index = torch.from_numpy(np.concatenate(edge_index).astype(np.int32)).long()\n",
    "    node_index = torch.from_numpy(np.concatenate(node_index)).long()\n",
    "\n",
    "    coupling_value = torch.from_numpy(np.concatenate(coupling_value)).float()\n",
    "    coupling_index = np.concatenate([\n",
    "        np.concatenate(coupling_atom_index),\n",
    "        np.concatenate(coupling_type_index).reshape(-1,1),\n",
    "        np.concatenate(coupling_batch_index).reshape(-1,1),\n",
    "    ],-1)\n",
    "    coupling_index = torch.from_numpy(coupling_index).long()\n",
    "    return node, edge, edge_index, node_index, coupling_value, coupling_index, infor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_collate2(batch):\n",
    "    batch_size = len(batch)\n",
    "\n",
    "    node = []\n",
    "    edge = []\n",
    "    edge_index = []\n",
    "    node_index = []\n",
    "\n",
    "    coupling_value = []\n",
    "    coupling_atom_index  = []\n",
    "    coupling_type_index  = []\n",
    "    coupling_batch_index = []\n",
    "    infor = []\n",
    "    mc = []\n",
    "\n",
    "    offset = 0\n",
    "    for b in range(batch_size):\n",
    "        graph = batch[b]\n",
    "        #print(graph.molecule_name)\n",
    "\n",
    "        num_node = len(graph[g_node_idx])\n",
    "        node.append(graph[g_node_idx])\n",
    "        edge.append(graph[g_edge_idx])\n",
    "        edge_index.append(graph[g_edge_index_idx]+offset)\n",
    "        node_index.append(np.array([b]*num_node))\n",
    "\n",
    "        num_coupling = len(graph[g_coupling_idx][0])\n",
    "        coupling_value.append(graph[g_coupling_idx][c_value_idx])\n",
    "        coupling_atom_index.append(graph[g_coupling_idx][c_index_idx]+offset)\n",
    "        coupling_type_index.append (graph[g_coupling_idx][c_type_idx])\n",
    "        coupling_batch_index.append(np.array([b]*num_coupling))\n",
    "\n",
    "        infor.append((graph[g_molecule_name_idx], graph[g_smile_idx], graph[g_coupling_idx][c_id_idx]))\n",
    "        offset += num_node\n",
    "        mc.append(mc_dict[graph[g_molecule_name_idx]])\n",
    "\n",
    "    node = torch.from_numpy(np.concatenate(node)).float()\n",
    "    edge = torch.from_numpy(np.concatenate(edge)).float()\n",
    "    edge_index = torch.from_numpy(np.concatenate(edge_index).astype(np.int32)).long()\n",
    "    node_index = torch.from_numpy(np.concatenate(node_index)).long()\n",
    "\n",
    "    coupling_value = torch.from_numpy(np.concatenate(coupling_value)).float()\n",
    "    coupling_index = np.concatenate([\n",
    "        np.concatenate(coupling_atom_index),\n",
    "        np.concatenate(coupling_type_index).reshape(-1,1),\n",
    "        np.concatenate(coupling_batch_index).reshape(-1,1),\n",
    "    ],-1)\n",
    "    coupling_index = torch.from_numpy(coupling_index).long()\n",
    "    # add mulliken charge\n",
    "    mc = torch.from_numpy(np.concatenate(mc)).float()\n",
    "\n",
    "    return node, edge, edge_index, node_index, coupling_value, coupling_index, infor, mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34matoms-graph\u001b[0m/  \u001b[01;34mchamps-scalar-coupling\u001b[0m/  \u001b[01;34mgraph-v5\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls ../input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = pd.read_csv(\"../input/champs-scalar-coupling/mulliken_charges.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5c71bc1da84908bc8bee4190b3d7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=85003), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_dict = {}\n",
    "mc_gr = mc.groupby(\"molecule_name\")\n",
    "for molecule_name in tqdm(mc[\"molecule_name\"].unique()):\n",
    "    mc_dict[molecule_name] = mc_gr.get_group(molecule_name)[\"mulliken_charge\"].values\n",
    "del mc, mc_gr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_valid(net, valid_loader):\n",
    "\n",
    "    valid_num = 0\n",
    "    valid_predict = []\n",
    "    valid_coupling_type  = []\n",
    "    valid_coupling_value = []\n",
    "\n",
    "    valid_loss = 0\n",
    "    for b, (node, edge, edge_index, node_index, coupling_value, coupling_index, infor,mc) in enumerate(valid_loader):\n",
    "\n",
    "        #if b==5: break\n",
    "        net.eval()\n",
    "        node = node.cuda()\n",
    "        edge = edge.cuda()\n",
    "        edge_index = edge_index.cuda()\n",
    "        node_index = node_index.cuda()\n",
    "\n",
    "        coupling_value = coupling_value.cuda()\n",
    "        coupling_index = coupling_index.cuda()\n",
    "        \n",
    "        mc = mc.cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predict, mc_predict = net(node, edge, edge_index, node_index, coupling_index)\n",
    "            \n",
    "            \n",
    "            coupling_atom0_index, coupling_atom1_index, coupling_type_index, coupling_batch_index = \\\n",
    "                        torch.split(coupling_index,1,dim=1)\n",
    "            \n",
    "            \n",
    "            loss = criterion(predict, coupling_value, mc_predict, mc)\n",
    "            #loss = criterion(predict, coupling_value)\n",
    "\n",
    "        #---\n",
    "        batch_size = len(infor)\n",
    "        valid_predict.append(predict.data.cpu().numpy())\n",
    "        valid_coupling_type.append(coupling_index[:,2].data.cpu().numpy())\n",
    "        valid_coupling_value.append(coupling_value.data.cpu().numpy())\n",
    "\n",
    "        valid_loss += batch_size*loss.item()\n",
    "        valid_num  += batch_size\n",
    "\n",
    "        print('\\r %8d /%8d'%(valid_num, len(valid_loader.dataset)),end='',flush=True)\n",
    "\n",
    "        pass  #-- end of one data loader --\n",
    "    assert(valid_num == len(valid_loader.dataset))\n",
    "    #print('')\n",
    "    valid_loss = valid_loss/valid_num\n",
    "\n",
    "    #compute\n",
    "    predict = np.concatenate(valid_predict)\n",
    "    coupling_value = np.concatenate(valid_coupling_value)\n",
    "    coupling_type  = np.concatenate(valid_coupling_type).astype(np.int32)\n",
    "    mae, log_mae   = compute_kaggle_metric( predict, coupling_value, coupling_type,)\n",
    "\n",
    "    num_target = 8\n",
    "    for t in range(8):\n",
    "        if mae[t] is None:\n",
    "            mae[t] = 0\n",
    "            log_mae[t]  = 0\n",
    "            num_target -= 1\n",
    "\n",
    "    mae_mean, log_mae_mean = sum(mae)/num_target, sum(log_mae)/num_target\n",
    "    #list(np.stack([mae, log_mae]).T.reshape(-1))\n",
    "\n",
    "    valid_loss = log_mae + [valid_loss,mae_mean, log_mae_mean, ]\n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train():\n",
    "    PROJECT_PATH = \"./\"\n",
    "    out_dir = \\\n",
    "        './result/kaggle_predict5.1-a'\n",
    "\n",
    "    initial_checkpoint = \\\n",
    "        None\n",
    "\n",
    "\n",
    "    schduler = NullScheduler(lr=0.001)\n",
    "\n",
    "    ## setup  -----------------------------------------------------------------------------\n",
    "    os.makedirs(out_dir +'/checkpoint', exist_ok=True)\n",
    "    os.makedirs(out_dir +'/train', exist_ok=True)\n",
    "    os.makedirs(out_dir +'/backup', exist_ok=True)\n",
    "    #backup_project_as_zip(PROJECT_PATH, out_dir +'/backup/code.train.%s.zip'%IDENTIFIER)\n",
    "\n",
    "    log = Logger()\n",
    "    log.open(out_dir+'/log.train.txt',mode='a')\n",
    "    log.write('\\n--- [START %s] %s\\n\\n' % (IDENTIFIER, '-' * 64))\n",
    "    log.write('\\t%s\\n' % COMMON_STRING)\n",
    "    log.write('\\n')\n",
    "\n",
    "    log.write('\\tSEED         = %u\\n' % SEED)\n",
    "    log.write('\\tPROJECT_PATH = %s\\n' % PROJECT_PATH)\n",
    "    #log.write('\\t__file__     = %s\\n' % __file__)\n",
    "    log.write('\\tout_dir      = %s\\n' % out_dir)\n",
    "    log.write('\\n')\n",
    "\n",
    "\n",
    "    ## dataset ----------------------------------------\n",
    "    log.write('** dataset setting **\\n')\n",
    "    batch_size = 20 #*2 #280*2 #256*4 #128 #256 #512  #16 #32\n",
    "\n",
    "    train_split, valid_split = get_split(FOLD_IDX)\n",
    "    \n",
    "    #train_split = train_split[:100]\n",
    "    #valid_split = valid_split[:100]\n",
    "\n",
    "    train_dataset = ChampsDataset(\n",
    "                csv='train',\n",
    "                mode ='train',\n",
    "                split = train_split,\n",
    "                #split='debug_split_by_mol.1000.npy', #\n",
    "                #split='train_split_by_mol.80003.npy',\n",
    "                augment=None,\n",
    "    )\n",
    "    train_loader  = DataLoader(\n",
    "                train_dataset,\n",
    "                #sampler     = SequentialSampler(train_dataset),\n",
    "                sampler     = RandomSampler(train_dataset),\n",
    "                batch_size  = batch_size,\n",
    "                drop_last   = True,\n",
    "                num_workers = 16,\n",
    "                pin_memory  = True,\n",
    "                collate_fn  = null_collate2\n",
    "    )\n",
    "\n",
    "    valid_dataset = ChampsDataset(\n",
    "                csv='train',\n",
    "                mode='train',\n",
    "                split = valid_split,\n",
    "                #split='debug_split_by_mol.1000.npy', # #,None\n",
    "                #split='valid_split_by_mol.5000.npy',\n",
    "                augment=None,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "                valid_dataset,\n",
    "                #sampler     = SequentialSampler(valid_dataset),\n",
    "                sampler     = RandomSampler(valid_dataset),\n",
    "                batch_size  = batch_size,\n",
    "                drop_last   = False,\n",
    "                num_workers = 0,\n",
    "                pin_memory  = True,\n",
    "                collate_fn  = null_collate2\n",
    "    )\n",
    "\n",
    "\n",
    "    assert(len(train_dataset)>=batch_size)\n",
    "    log.write('batch_size = %d\\n'%(batch_size))\n",
    "    log.write('train_dataset : \\n%s\\n'%(train_dataset))\n",
    "    log.write('valid_dataset : \\n%s\\n'%(valid_dataset))\n",
    "    log.write('\\n')\n",
    "\n",
    "    ## net ----------------------------------------\n",
    "    log.write('** net setting **\\n')\n",
    "    net = Net3(node_dim=NODE_DIM,edge_dim=EDGE_DIM, num_target=NUM_TARGET).cuda()\n",
    "\n",
    "    log.write('\\tinitial_checkpoint = %s\\n' % initial_checkpoint)\n",
    "    if initial_checkpoint is not None:\n",
    "        net.load_state_dict(torch.load(initial_checkpoint, map_location=lambda storage, loc: storage))\n",
    "\n",
    "    log.write('%s\\n'%(type(net)))\n",
    "    log.write('\\n')\n",
    "\n",
    "    # pretrain_file = '/root/share/project/kaggle/2019/champs_scalar/result/backup/00370000_model.pth'\n",
    "    # load_pretrain(net,pretrain_file)\n",
    "\n",
    "    ## optimiser ----------------------------------\n",
    "    # if 0: ##freeze\n",
    "    #     for p in net.encoder1.parameters(): p.requires_grad = False\n",
    "    #     pass\n",
    "\n",
    "    #net.set_mode('train',is_freeze_bn=True)\n",
    "    #-----------------------------------------------\n",
    "\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()),lr=schduler(0))\n",
    "    #optimizer = torch.optim.RMSprop(net.parameters(), lr =0.0005, alpha = 0.95)\n",
    "    #optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, net.parameters()), lr=schduler(0), momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "    iter_accum  = 1\n",
    "    num_iters   = 3000  *15#00\n",
    "    iter_smooth = 50\n",
    "    iter_log    = 1000\n",
    "    iter_valid  = 1000\n",
    "    iter_save   = [0, num_iters-1]\\\n",
    "                   + list(range(0, num_iters, 2500))#1*1000\n",
    "\n",
    "    start_iter = 0\n",
    "    start_epoch= 0\n",
    "    rate       = 0\n",
    "    if initial_checkpoint is not None:\n",
    "        initial_optimizer = initial_checkpoint.replace('_model.pth','_optimizer.pth')\n",
    "        if os.path.exists(initial_optimizer):\n",
    "            checkpoint  = torch.load(initial_optimizer)\n",
    "            start_iter  = checkpoint['iter' ]\n",
    "            start_epoch = checkpoint['epoch']\n",
    "\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "    log.write('optimizer\\n  %s\\n'%(optimizer))\n",
    "    log.write('schduler\\n  %s\\n'%(schduler))\n",
    "    log.write('\\n')\n",
    "\n",
    "    ## start training here! ##############################################\n",
    "\n",
    "    log.write('** start training here! **\\n')\n",
    "    log.write('   batch_size =%d,  iter_accum=%d\\n'%(batch_size,iter_accum))\n",
    "    log.write('                      |--------------- VALID ----------------------------------------------------------------|-- TRAIN/BATCH ---------\\n')\n",
    "    log.write('                      |std %4.1f    %4.1f    %4.1f    %4.1f    %4.1f    %4.1f    %4.1f   %4.1f  |                    |        | \\n'%tuple(COUPLING_TYPE_STD))\n",
    "    log.write('rate     iter   epoch |    1JHC,   2JHC,   3JHC,   1JHN,   2JHN,   3JHN,   2JHH,   3JHH |  loss  mae log_mae | loss   | time          \\n')\n",
    "    log.write('--------------------------------------------------------------------------------------------------------------------------------------\\n')\n",
    "              #0.00100  111.0* 111.0 | 1.0 +1.2, 2.0 +1.2, 3.0 +1.2, 4.0 +1.2, 5.0 +1.2, 6.0 +1.2, 7.0 +1.2, 8.0 +1.2 | 8.01 +1.21  5.620 | 5.620 | 0 hr 04 min\n",
    "               #    %5.2f     %5.2f     %5.2f     %5.2f     %5.2f     %5.2f     %5.2f     %5.2f\n",
    "\n",
    "    train_loss   = np.zeros(20,np.float32)\n",
    "    valid_loss   = np.zeros(20,np.float32)\n",
    "    batch_loss   = np.zeros(20,np.float32)\n",
    "    iter = 0\n",
    "    i    = 0\n",
    "\n",
    "\n",
    "    start = timer()\n",
    "    while  iter<num_iters:\n",
    "        sum_train_loss = np.zeros(20,np.float32)\n",
    "        sum = 0\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        for node, edge, edge_index, node_index, coupling_value, coupling_index, infor, mc in train_loader:\n",
    "\n",
    "            #while 1:\n",
    "                batch_size = len(infor)\n",
    "                iter  = i + start_iter\n",
    "                epoch = (iter-start_iter)*batch_size/len(train_dataset) + start_epoch\n",
    "\n",
    "\n",
    "                # debug-----------------------------\n",
    "                # if 0:\n",
    "                #     pass\n",
    "\n",
    "                #if 0:\n",
    "                if (iter % iter_valid==0):\n",
    "                    valid_loss = do_valid(net, valid_loader) #\n",
    "                #print(valid_loss,flush=True)\n",
    "\n",
    "\n",
    "                if (iter % iter_log==0):\n",
    "                    print('\\r',end='',flush=True)\n",
    "\n",
    "                    asterisk = '*' if iter in iter_save else ' '\n",
    "                    log.write('%0.5f  %5.1f%s %5.1f |  %+0.3f, %+0.3f, %+0.3f, %+0.3f, %+0.3f, %+0.3f, %+0.3f, %+0.3f | %+5.3f %5.2f %+0.2f | %+5.3f | %s' % (\\\n",
    "                             rate, iter/1000, asterisk, epoch,\n",
    "                             *valid_loss[:11],\n",
    "                             train_loss[0],\n",
    "                             time_to_str((timer() - start),'min'))\n",
    "                    )\n",
    "                    log.write('\\n')\n",
    "\n",
    "\n",
    "                #if 0:\n",
    "                if iter in iter_save:\n",
    "                    torch.save(net.state_dict(),out_dir +'/checkpoint/%08d_model.pth'%(iter))\n",
    "                    torch.save({\n",
    "                        'optimizer': optimizer.state_dict(),\n",
    "                        'iter'     : iter,\n",
    "                        'epoch'    : epoch,\n",
    "                    }, out_dir +'/checkpoint/%08d_optimizer.pth'%(iter))\n",
    "                    pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # learning rate schduler -------------\n",
    "                lr = schduler(iter)\n",
    "                if lr<0 : break\n",
    "                adjust_learning_rate(optimizer, lr)\n",
    "                rate = get_learning_rate(optimizer)\n",
    "\n",
    "                # one iteration update  -------------\n",
    "                #net.set_mode('train',is_freeze_bn=True)\n",
    "\n",
    "                net.train()\n",
    "                node = node.cuda()\n",
    "                edge = edge.cuda()\n",
    "                edge_index = edge_index.cuda()\n",
    "                node_index = node_index.cuda()\n",
    "                coupling_value = coupling_value.cuda()\n",
    "                coupling_index = coupling_index.cuda()\n",
    "                mc = mc.cuda()\n",
    "\n",
    "\n",
    "                predict, mc_predict = net(node, edge, edge_index, node_index, coupling_index)\n",
    "                \n",
    "                coupling_atom0_index, coupling_atom1_index, coupling_type_index, coupling_batch_index = \\\n",
    "                            torch.split(coupling_index,1,dim=1)\n",
    "                                \n",
    "                loss = criterion(predict, coupling_value, mc_predict, mc)\n",
    "\n",
    "                (loss/iter_accum).backward()\n",
    "                if (iter % iter_accum)==0:\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                # print statistics  ------------\n",
    "                batch_loss[:1] = [loss.item()]\n",
    "                sum_train_loss += batch_loss\n",
    "                sum += 1\n",
    "                if iter%iter_smooth == 0:\n",
    "                    train_loss = sum_train_loss/sum\n",
    "                    sum_train_loss = np.zeros(20,np.float32)\n",
    "                    sum = 0\n",
    "\n",
    "            \n",
    "                print('\\r',end='',flush=True)\n",
    "                asterisk = ' '\n",
    "                print('%0.5f  %5.1f%s %5.1f |  %+0.3f, %+0.3f, %+0.3f, %+0.3f, %+0.3f, %+0.3f, %+0.3f, %+0.3f | %+5.3f %5.2f %+0.2f | %+5.3f | %s' % (\\\n",
    "                             rate, iter/1000, asterisk, epoch,\n",
    "                             *valid_loss[:11],\n",
    "                             batch_loss[0],\n",
    "                             time_to_str((timer() - start),'min'))\n",
    "                , end='',flush=True)\n",
    "                i=i+1\n",
    "\n",
    "\n",
    "        pass  #-- end of one data loader --\n",
    "    pass #-- end of all iterations --\n",
    "\n",
    "    log.write('\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDENTIFIER = 1\n",
    "NODE_DIM=99#126#113#93 # 13 + 80(acsf)\n",
    "EDGE_DIM=10\n",
    "COUPLING_TYPE_STATS=[\n",
    "    #type   #mean, std, min, max\n",
    "    '1JHC',  94.9761528641869,   18.27722399839607,   66.6008,   204.8800,\n",
    "    '2JHC',  -0.2706244378832,    4.52360876732858,  -36.2186,    42.8192,\n",
    "    '3JHC',   3.6884695895355,    3.07090647005439,  -18.5821,    76.0437,\n",
    "    '1JHN',  47.4798844844683,   10.92204561670947,   24.3222,    80.4187,\n",
    "    '2JHN',   3.1247536134185,    3.67345877025737,   -2.6209,    17.7436,\n",
    "    '3JHN',   0.9907298624944,    1.31538940138001,   -3.1724,    10.9712,\n",
    "    '2JHH', -10.2866051639817,    3.97960190019757,  -35.1761,    11.8542,\n",
    "    '3JHH',   4.7710233597359,    3.70498129755812,   -3.0205,    17.4841,\n",
    "]\n",
    "NUM_TARGET = len(COUPLING_TYPE_STATS)//5\n",
    "NUM_COUPLING_TYPE = NUM_TARGET\n",
    "\n",
    "COUPLING_TYPE_MEAN = [ COUPLING_TYPE_STATS[i*5+1] for i in range(NUM_TARGET)]\n",
    "COUPLING_TYPE_STD  = [ COUPLING_TYPE_STATS[i*5+2] for i in range(NUM_TARGET)]\n",
    "COUPLING_TYPE      = [ COUPLING_TYPE_STATS[i*5  ] for i in range(NUM_TARGET)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- [START 1] ----------------------------------------------------------------\n",
      "\n",
      "\t\tset random seed\n",
      "\t\tSEED = 1564744342\n",
      "\tset cuda environment\n",
      "\t\ttorch.__version__              = 1.1.0\n",
      "\t\ttorch.version.cuda             = 10.0.130\n",
      "\t\ttorch.backends.cudnn.version() = 7501\n",
      "\t\tos['CUDA_VISIBLE_DEVICES']     = None\n",
      "\t\ttorch.cuda.device_count()      = 1\n",
      "\n",
      "\n",
      "\tSEED         = 1564744342\n",
      "\tPROJECT_PATH = ./\n",
      "\tout_dir      = ./result/kaggle_predict5.1-a\n",
      "\n",
      "** dataset setting **\n",
      "batch_size = 20\n",
      "train_dataset : \n",
      "\tmode   = train\n",
      "\tsplit  = ['dsgdb9nsd_000001' 'dsgdb9nsd_000002' 'dsgdb9nsd_000003' ...\n",
      " 'dsgdb9nsd_133880' 'dsgdb9nsd_133881' 'dsgdb9nsd_133882']\n",
      "\tcsv    = train\n",
      "\tlen    = 56669\n",
      "\n",
      "valid_dataset : \n",
      "\tmode   = train\n",
      "\tsplit  = ['dsgdb9nsd_000007' 'dsgdb9nsd_000011' 'dsgdb9nsd_000018' ...\n",
      " 'dsgdb9nsd_133874' 'dsgdb9nsd_133876' 'dsgdb9nsd_133884']\n",
      "\tcsv    = train\n",
      "\tlen    = 28334\n",
      "\n",
      "\n",
      "** net setting **\n",
      "\tinitial_checkpoint = None\n",
      "<class '__main__.Net3'>\n",
      "\n",
      "optimizer\n",
      "  Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "schduler\n",
      "  NullScheduler\n",
      "lr=0.00100 \n",
      "\n",
      "** start training here! **\n",
      "   batch_size =20,  iter_accum=1\n",
      "                      |--------------- VALID ----------------------------------------------------------------|-- TRAIN/BATCH ---------\n",
      "                      |std 18.3     4.5     3.1    10.9     3.7     1.3     4.0    3.7  |                    |        | \n",
      "rate     iter   epoch |    1JHC,   2JHC,   3JHC,   1JHN,   2JHN,   3JHN,   2JHH,   3JHH |  loss  mae log_mae | loss   | time          \n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "0.00000    0.0*   0.0 |  +4.554, +1.019, +1.321, +3.862, +1.211, +0.066, +2.355, +1.583 | +1.250 21.11 +2.00 | +0.000 |  0 hr 03 min\n",
      "0.00100    1.0    0.4 |  +0.991, -0.283, +0.100, +1.259, -0.525, -0.798, -0.090, +0.048 | -4.205  1.38 +0.09 | -4.004 |  0 hr 10 min\n",
      "0.00100    2.0    0.7 |  +1.103, -0.455, -0.142, +1.234, -0.702, -0.886, -0.474, -0.292 | -4.602  1.28 -0.08 | -4.456 |  0 hr 16 min\n",
      "0.00100    3.0    1.1 |  +0.667, -0.603, -0.263, +0.468, -0.871, -1.083, -0.506, -0.251 | -4.463  0.87 -0.31 | -4.820 |  0 hr 22 min\n",
      "    26500 /   28334"
     ]
    }
   ],
   "source": [
    "run_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp = list(read_pickle_from_file(\"../input/graph-v4/graph_v4/graph_v4/dsgdb9nsd_000001.pickle\"))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1d2e6637b78243cdba206446f75295b4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2419ad7c275742d78b4ea9079a23f919": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "36694975b6e447e0be71ebc540f5fc3e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3fcf5f1e33c6457db783d4f4d695bf92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "74d5c74221cf4217b43a706f70ec55e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2419ad7c275742d78b4ea9079a23f919",
       "max": 85003,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3fcf5f1e33c6457db783d4f4d695bf92",
       "value": 85003
      }
     },
     "d6580b58e83047adb235c928744dceb0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1d2e6637b78243cdba206446f75295b4",
       "placeholder": "​",
       "style": "IPY_MODEL_36694975b6e447e0be71ebc540f5fc3e",
       "value": "100% 85003/85003 [01:03&lt;00:00, 1344.86it/s]"
      }
     },
     "dcf09f68e8154a289f5de10ddb0b1a3e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ea5c71bc1da84908bc8bee4190b3d7a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_74d5c74221cf4217b43a706f70ec55e3",
        "IPY_MODEL_d6580b58e83047adb235c928744dceb0"
       ],
       "layout": "IPY_MODEL_dcf09f68e8154a289f5de10ddb0b1a3e"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
